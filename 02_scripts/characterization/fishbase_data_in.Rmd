---
title: "fishbase_data_in"
output: html_document
date: "2023-04-10"
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE, message=FALSE, warning=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)

library(tidyverse)
library(here)
library(rfishbase)
```

### Read in data

```{r}
data <- read_csv(here::here("01_data", "02_processed_data", "homerange_pld.csv")) %>%
  mutate(home_range = case_when(
    !is.na(observed_homerange) ~ observed_homerange,
    is.na(observed_homerange) ~ predicted_homerange
  )) %>%
  mutate(pld = case_when(
    !is.na(observed_pld) ~ observed_pld,
    is.na(observed_pld) ~ predicted_pld
  )) %>%
  filter(pld < 400) %>%
  mutate(magnitude_homerange = floor(log10(home_range))) %>%
  mutate(month_pld = ceiling(pld / 30))
```

```{r}
fish <- load_taxa() %>%  # load all taxonomic info from fishbase into fish, then
  filter(Species %in% data$species) # select only the rows containing species listed in data

# created a dataframe with 3 fewer rows?

order(data$species) # order the dataframes by species to look for missing species names
order(fish$Species)
data$species[!(data$species %in% fish$Species)] # find the species in data that are not included in fish

# 3 species not included in fish: Limanda ferruginea, Oblada melanura, Pennahia anea
```

### collect diet variable

```{r}
# get diet items and combine rows of the same species in each column
diet <- fooditems(fish$Species, fields = c("Species", "FoodI", "FoodII", "FoodIII")) %>% 
  group_by(Species) %>%
  summarise(FoodI = paste(unique(FoodI), collapse = ", "), 
            FoodII = paste(unique(FoodII), collapse = ", "), 
            FoodIII = paste(unique(FoodIII), collapse = ", ")) %>% 
  ungroup()

# using unique(x) makes sure there are not duplicates

diet <- janitor::clean_names(diet)
```

### Add diet columns to data

```{r}
data <- left_join(data,diet) %>% 
  select(-food_ii, -food_iii)
```

### collect location variable

```{r}
# get location data (lat and long)
coords <- stocks() %>%  # load stocks info, then
  filter(SpecCode %in% fish$SpecCode) %>%  # filter rows by specCodes in fish, then
  select(SpecCode, Northernmost, NorthSouthN, Southermost, NorthSouthS, Westernmost,
           WestEastW, Easternmost, WestEastE) # select columns

coords <- na.omit(coords) # remove NA values

# not sure if I need to make everything uppercase?

coords <- data.frame(lapply(coords, function(v) {
  if (is.character(v)) return(toupper(v))
  else return(v)
}))

# there are a few spec codes listed more than once. 
# can I delete the duplicated rows..? there are only 5 <-----------------------------------------------

coords_clean <- coords[!duplicated(coords$SpecCode), ]

# add coords to fish because they share a column
fish <- left_join(fish, coords_clean)

fish <- janitor::clean_names(fish)
```

### Add location columns to data

```{r}
data <- left_join(data, fish) %>% 
  select(-spec_code, -genus, -subfamily, -family, -order, -class, -super_class)
```


### Old
```{r}
# can I average the lat/long values and delete the duplicated rows? <--------------- NO. bc this messes with the E/W delineation

# mean_stocks <- stocks %>% 
  # group_by(SpecCode) %>% 
  # summarise(Northernmost = mean(Northernmost), NorthSouthN = NorthSouthN, Southernmost =
             # mean(Southermost),NorthSouthS = NorthSouthS, Westernmost = mean(Westernmost), WestEastW =
             # WestEastW, Easternmost = mean(Easternmost), WestEastE = WestEastE) %>% 
  # ungroup()
```




